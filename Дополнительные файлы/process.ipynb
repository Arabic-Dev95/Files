{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-awRcnxHC7HX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b40974c"
      },
      "source": [
        "# Обработка текста"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cee2ae35"
      },
      "outputs": [],
      "source": [
        "import pymorphy2\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b10e3a34"
      },
      "outputs": [],
      "source": [
        "sw = stopwords.words('russian')\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def clear_text(text):\n",
        "    text=text.lower()\n",
        "    text = re.sub(r'[^а-яё ]','', str(text))\n",
        "    tokens=word_tokenize(text, language=\"russian\")\n",
        "    tokens = [morph.parse(i)[0].normal_form for i in tokens]\n",
        "    tokens = [ i for i in tokens if i not in sw and len(i) > 3]\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7eaf47e"
      },
      "outputs": [],
      "source": [
        "tk['lemmatize_tokens'] = tk['Post'].apply(clear_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37b23768"
      },
      "outputs": [],
      "source": [
        "tk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a7ab516"
      },
      "outputs": [],
      "source": [
        "tk['clear_text'] = tk['lemmatize_tokens'].apply(lambda x: \" \".join(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95b1a5ea"
      },
      "outputs": [],
      "source": [
        "tk.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dff1d5f"
      },
      "outputs": [],
      "source": [
        "tk.to_csv('data.csv', index=False)"
      ]
    }
  ]
}